{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def one_hot_label(img):\n",
    "    # img is the file name of a configuration\n",
    "    label, T, _, = img.split('_')\n",
    "    if label == 'low':\n",
    "        ohl = np.array([1, 0])\n",
    "    elif label == 'high':\n",
    "        ohl = np.array([0, 1])\n",
    "    return ohl, T\n",
    "\n",
    "def data_with_label(data_path, *args):\n",
    "    data = []\n",
    "    if args:  # The args are the categories in the data path that separate the classes/categories\n",
    "        for category in args:\n",
    "            category_path = os.path.join(data_path, category)  # Category folder\n",
    "            for i in tqdm(os.listdir(category_path)):\n",
    "                path = os.path.join(category_path, i) \n",
    "                img = np.load(path)  # Assuming the files are NumPy arrays\n",
    "                data.append([img.astype(dtype='float32'), one_hot_label(i)])\n",
    "        shuffle(data)\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r'C:\\Users\\frenc\\Documents\\dottorato\\ising\\train'\n",
    "\n",
    "valid_path = r'C:\\Users\\frenc\\Documents\\dottorato\\ising\\validation'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7000/7000 [00:01<00:00, 4051.52it/s]\n",
      "100%|██████████| 8000/8000 [00:01<00:00, 7129.44it/s]\n",
      "100%|██████████| 1400/1400 [00:00<00:00, 7003.24it/s]\n",
      "100%|██████████| 1600/1600 [00:00<00:00, 6242.14it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_set = data_with_label(train_path, 'low', 'high')\n",
    "\n",
    "valid_set = data_with_label(valid_path, 'low', 'high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_img_data = np.array([i[0] for i in train_set])\n",
    "tr_lbl_data = np.array([i[1][0] for i in train_set])\n",
    "tr_Temp_data = np.array([i[1][1] for i in train_set])\n",
    "val_img_data = np.array([i[0] for i in valid_set])\n",
    "val_lbl_data = np.array([i[1][0] for i in valid_set])\n",
    "val_Temp_data = np.array([float(i[1][1]) for i in valid_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `tr_img_data` and `tr_lbl_data` are already loaded numpy arrays\n",
    "train_images = torch.tensor(tr_img_data, dtype=torch.float32)  # Input data (e.g., (N, 20, 20))\n",
    "train_labels = torch.tensor(tr_lbl_data, dtype=torch.float32)  # Labels (e.g., (N,))\n",
    "val_images = torch.tensor(val_img_data, dtype=torch.float32)  # Input data (e.g., (N, 20, 20))\n",
    "val_labels = torch.tensor(val_lbl_data, dtype=torch.float32)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(predictions, true_labels):\n",
    "    # Convert predictions and true_labels into numpy arrays if they aren't already\n",
    "    \n",
    "    predictions = predictions.detach().cpu().numpy()  # Move to CPU and detach from the graph\n",
    "    true_labels = true_labels.detach().cpu().numpy() \n",
    "\n",
    "    # Calculate the number of correct predictions\n",
    "    correct_predictions = np.sum(np.argmax(predictions, axis=1) == np.argmax(true_labels, axis=1))\n",
    "    total_predictions = len(predictions)\n",
    "\n",
    "    # Return accuracy\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_images, train_labels, val_images, val_labels, epochs=15, batch_size=32, lr=0.001):\n",
    "    \"\"\"\n",
    "    Train a model using the provided training data.\n",
    "\n",
    "    Parameters:\n",
    "        model: The model to train (instance of nn.Module).\n",
    "        train_images: Tensor of input data (e.g., shape (N, 20, 20)).\n",
    "        train_labels: Tensor of labels (e.g., shape (N,)).\n",
    "        val_images: Tensor of validation images.\n",
    "        val_labels: Tensor of validation labels.\n",
    "        epochs: Number of training epochs.\n",
    "        batch_size: Batch size for training.\n",
    "        lr: Learning rate.\n",
    "    \"\"\"\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Convert to the correct device (GPU if available)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    train_images, train_labels = train_images.to(device), train_labels.to(device)\n",
    "    val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        epoch_loss = 0 \n",
    "        accuracy_epoch = []\n",
    "        \n",
    "        # Shuffle data and iterate in mini-batches\n",
    "        perm = torch.randperm(train_images.size(0))\n",
    "        for i in range(0, len(train_images), batch_size):\n",
    "            indices = perm[i:i+batch_size]\n",
    "            batch_images, batch_labels = train_images[indices], train_labels[indices]\n",
    "\n",
    "            # Forward pass: Compute predicted y by passing x to the model\n",
    "            outputs = model(batch_images)\n",
    "            \n",
    "            accuracy = calculate_accuracy(outputs, batch_labels)\n",
    "            # Calculate the loss\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            # Zero gradients, backward pass, optimizer step\n",
    "            optimizer.zero_grad()  # Clear previous gradients\n",
    "            loss.backward()  # Backpropagate the loss\n",
    "            optimizer.step()  # Update the model parameters\n",
    "            accuracy_epoch.append(accuracy)\n",
    "        \n",
    "        # Calculate average loss and accuracy for the epoch\n",
    "        epoch_loss = epoch_loss / (len(train_images) // batch_size)\n",
    "        accuracy_epoch = np.mean(accuracy_epoch)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        with torch.no_grad():  # No need to compute gradients during validation\n",
    "            val_outputs = model(val_images)\n",
    "            val_loss = criterion(val_outputs, val_labels)\n",
    "            val_accuracy = calculate_accuracy(val_outputs, val_labels)\n",
    "\n",
    "        # Print loss and accuracy statistics after each epoch\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {epoch_loss:.4f}, Train Accuracy: {accuracy_epoch:.4f}, \"\n",
    "              f\"Val Loss: {val_loss.item():.4f}, Val Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DenseNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(DenseNetwork, self).__init__()\n",
    "        # Flatten layer isn't needed in PyTorch, input shape is handled in the forward pass\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(20 * 20, 100)  # Flattened 20x20 input to 10 output\n",
    "        self.fc2 = nn.Linear(100, 2)  # 10 to 2 outputs\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = torch.sigmoid(self.fc1(x))  # Sigmoid activation\n",
    "        x = self.fc2(x) \n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        return x  # Apply softmax activation on the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 0.6756, Train Accuracy: 0.5631, Val Loss: 0.6202, Val Accuracy: 0.7067\n",
      "Epoch 2/20, Train Loss: 0.4709, Train Accuracy: 0.8869, Val Loss: 0.3453, Val Accuracy: 0.9220\n",
      "Epoch 3/20, Train Loss: 0.2664, Train Accuracy: 0.9200, Val Loss: 0.2333, Val Accuracy: 0.9200\n",
      "Epoch 4/20, Train Loss: 0.2044, Train Accuracy: 0.9292, Val Loss: 0.1999, Val Accuracy: 0.9290\n",
      "Epoch 5/20, Train Loss: 0.1798, Train Accuracy: 0.9360, Val Loss: 0.1874, Val Accuracy: 0.9337\n",
      "Epoch 6/20, Train Loss: 0.1642, Train Accuracy: 0.9406, Val Loss: 0.2089, Val Accuracy: 0.9227\n",
      "Epoch 7/20, Train Loss: 0.1547, Train Accuracy: 0.9417, Val Loss: 0.1833, Val Accuracy: 0.9303\n",
      "Epoch 8/20, Train Loss: 0.1434, Train Accuracy: 0.9446, Val Loss: 0.1786, Val Accuracy: 0.9327\n",
      "Epoch 9/20, Train Loss: 0.1325, Train Accuracy: 0.9486, Val Loss: 0.1832, Val Accuracy: 0.9270\n",
      "Epoch 10/20, Train Loss: 0.1240, Train Accuracy: 0.9523, Val Loss: 0.1766, Val Accuracy: 0.9323\n",
      "Epoch 11/20, Train Loss: 0.1168, Train Accuracy: 0.9555, Val Loss: 0.1805, Val Accuracy: 0.9307\n",
      "Epoch 12/20, Train Loss: 0.1076, Train Accuracy: 0.9584, Val Loss: 0.1841, Val Accuracy: 0.9280\n",
      "Epoch 13/20, Train Loss: 0.1004, Train Accuracy: 0.9613, Val Loss: 0.1828, Val Accuracy: 0.9320\n",
      "Epoch 14/20, Train Loss: 0.0947, Train Accuracy: 0.9649, Val Loss: 0.1848, Val Accuracy: 0.9280\n",
      "Epoch 15/20, Train Loss: 0.0848, Train Accuracy: 0.9693, Val Loss: 0.1992, Val Accuracy: 0.9293\n",
      "Epoch 16/20, Train Loss: 0.0790, Train Accuracy: 0.9717, Val Loss: 0.1914, Val Accuracy: 0.9290\n",
      "Epoch 17/20, Train Loss: 0.0716, Train Accuracy: 0.9758, Val Loss: 0.1978, Val Accuracy: 0.9283\n",
      "Epoch 18/20, Train Loss: 0.0666, Train Accuracy: 0.9789, Val Loss: 0.1890, Val Accuracy: 0.9333\n",
      "Epoch 19/20, Train Loss: 0.0600, Train Accuracy: 0.9813, Val Loss: 0.2118, Val Accuracy: 0.9277\n",
      "Epoch 20/20, Train Loss: 0.0552, Train Accuracy: 0.9852, Val Loss: 0.1942, Val Accuracy: 0.9347\n"
     ]
    }
   ],
   "source": [
    "model = DenseNetwork()\n",
    "\n",
    "# Call the train function\n",
    "train_model(model,\n",
    "            train_images,\n",
    "            train_labels, \n",
    "            val_images = val_images, \n",
    "            val_labels = val_labels, \n",
    "            epochs = 20, \n",
    "            batch_size = 32,\n",
    "            lr = 0.001\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
